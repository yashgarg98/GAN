{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAZ47WmVY1jy"
      },
      "source": [
        "##################### implementation of info GAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDqGURl9Y2qC"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import itertools\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uImlXwUeZAgg"
      },
      "source": [
        "batch_size=100\n",
        "# transform = transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize(mean=(0.5, ), std=(0.5, ))])\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor()\n",
        "])\n",
        "train_data = torchvision.datasets.MNIST('/content/', train = True,\n",
        "                           transform=transform, download = True)\n",
        "test_data = torchvision.datasets.MNIST('/content/', train = False,\n",
        "                           transform=transform, download = True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C-0wIoKZAjb"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz=74):\n",
        "      super(Generator, self).__init__()\n",
        "      self.l1 = nn.Linear(74, 1024, bias=False)\n",
        "      # self.conv1 = nn.ConvTranspose2d(nz,1024,1,1, bias=False)\n",
        "      self.b1 = nn.BatchNorm1d(1024)\n",
        "\n",
        "      self.l2 = nn.Linear(1024,7*7*128, bias=False)\n",
        "      # self.conv2 = nn.ConvTranspose2d(1024,128,7,1, bias=False)\n",
        "      self.b2 = nn.BatchNorm2d(128)\n",
        "\n",
        "      self.up1 = nn.ConvTranspose2d(128,64,4,stride=2,padding=1, bias=False)\n",
        "      self.b3 = nn.BatchNorm2d(64)\n",
        "      \n",
        "      self.up2 = nn.ConvTranspose2d(64,1,4,stride=2,padding=1, bias=False)\n",
        "  \n",
        "    def forward(self, input):\n",
        "      output = self.b1(F.relu(self.l1(input)))\n",
        "      # output = F.relu(output)\n",
        "      # output = self.b1(output)\n",
        "      output = self.l2(output)\n",
        "      output = output.view(-1,128,7,7)\n",
        "      output = self.b2(F.relu(output))\n",
        "      output = self.b3(F.relu(self.up1(output)))\n",
        "      output = torch.sigmoid(self.up2(output))\n",
        "      # print(output.shape)\n",
        "      return output\n",
        "\n",
        "class DQ_common(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(DQ_common, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(1,64,4,stride=2,padding=1, bias=False)\n",
        "\n",
        "      self.conv2 = nn.Conv2d(64,128,4,stride=2,padding=1, bias=False)\n",
        "      self.b2 = nn.BatchNorm2d(128)\n",
        "\n",
        "      self.l1 = nn.Linear(7*7*128,1024)\n",
        "      self.b3 = nn.BatchNorm1d(1024)\n",
        "      # self.conv3 = nn.Conv2d(128, 1024, 7, bias=False)\n",
        "      # self.b3 = nn.BatchNorm2d(1024)\n",
        "\n",
        "    def forward(self,input):\n",
        "      output = F.leaky_relu(self.conv1(input), 0.1, inplace=True)\n",
        "      output = F.leaky_relu(self.conv2(output), 0.1, inplace=True)\n",
        "      output = self.b2(output)\n",
        "      output = output.view(-1,128*7*7)\n",
        "      # output = torch.flatten(output)\n",
        "      # print(output.shape)\n",
        "      output = self.b3(F.leaky_relu(self.l1(output), 0.1, inplace=True))\n",
        "      # print(output.shape)\n",
        "      return output\n",
        "\n",
        "class Dis(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Dis, self).__init__()\n",
        "      self.l1 = nn.Linear(1024,1)\n",
        "      # self.conv1 = nn.Conv2d(1024,1,1, bias=False)\n",
        "      \n",
        "    def forward(self,input):\n",
        "      output = torch.sigmoid(self.l1(input)).squeeze() #.view(-1,1)\n",
        "      return output\n",
        "\n",
        "class Qhead(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Qhead,self).__init__()\n",
        "      self.l1 = nn.Linear(1024,128)\n",
        "      # self.conv1 = nn.Conv2d(1024,128,1, bias=False)\n",
        "      self.b1 = nn.BatchNorm1d(128)\n",
        "      self.l2 = nn.Linear(128,12)\n",
        "      # self.conv2 = nn.Conv2d(128,10,1, bias=False)\n",
        "      # self.conv3 = nn.Conv2d(128,2,1, bias=False)\n",
        "      # self.conv4 = nn.Conv2d(128,2,1, bias=False)\n",
        "      \n",
        "    def forward(self, input):\n",
        "      out = F.leaky_relu(self.b1(self.l1(input)), 0.1, inplace=True)\n",
        "      out = self.l2(out)\n",
        "\n",
        "      # discrete = self.conv2(out).squeeze()\n",
        "      # mu = self.conv3(out).squeeze()\n",
        "      # var = torch.exp(self.conv4(out).squeeze())\n",
        "\n",
        "      # return discrete, mu, var\n",
        "      return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NomG1spSZM2l"
      },
      "source": [
        "import random\n",
        "seed=1123\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEH2JD2ZZM-R"
      },
      "source": [
        "def weights_init(m):\n",
        "    if(type(m) == nn.ConvTranspose2d or type(m) == nn.Conv2d):\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif(type(m) == nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "def noise_function(noise, con_c, dis_c, bs,device):\n",
        "\n",
        "    idx = np.random.randint(10, size=bs)\n",
        "    c = np.zeros((bs, 10))\n",
        "    c[range(bs),idx] = 1.0\n",
        "\n",
        "    dis_c.copy_(torch.Tensor(c))\n",
        "    # con_c.data.uniform_(-1.0, 1.0)\n",
        "    # noise.data.uniform_(-1.0, 1.0)\n",
        "    z = torch.cat([noise, dis_c, con_c], dim=1) #.view(-1, 74, 1, 1)\n",
        "    # z=z.to(device)\n",
        "    idx = torch.from_numpy(idx).to(device)\n",
        "    return z, idx\n",
        "\n",
        "\n",
        "\n",
        "def log_gaussian(x, mu, var):\n",
        "  logli = -0.5*(var.mul(2*np.pi)+1e-6).log() - (x-mu).pow(2).div(var.mul(2.0)+1e-6)\n",
        "\n",
        "  return logli.sum(1).mean().mul(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q4pzPfSZNHW"
      },
      "source": [
        "device='cuda'\n",
        "epochs=80\n",
        "nz=74\n",
        "# fixed_noise = torch.randn((16,nz,1,1),dtype=torch.float32,device=device)\n",
        "netGenerator = Generator().to(device)\n",
        "netGenerator.apply(weights_init)\n",
        "netDQ_common = DQ_common().to(device)\n",
        "netDQ_common.apply(weights_init)\n",
        "netDis = Dis().to(device)\n",
        "netDis.apply(weights_init)\n",
        "netQhead = Qhead().to(device)\n",
        "netQhead.apply(weights_init)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss() #nn.BCELoss()\n",
        "criterionQ_dis = nn.CrossEntropyLoss()\n",
        "# criterionQ_con = log_gaussian\n",
        "criterionQ_con = nn.MSELoss()\n",
        "\n",
        "real_label = torch.full((batch_size,),1,dtype=torch.float32,device=device)\n",
        "fake_label = torch.full((batch_size,),0,dtype=torch.float32,device=device)\n",
        "optimizer_g = optim.Adam([{'params': netGenerator.parameters()}, {'params': netQhead.parameters()}], lr=0.001)\n",
        "optimizer_d = optim.Adam([{'params': netDQ_common.parameters()}, {'params': netDis.parameters()}], lr=0.0002)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGC_069oZAoe"
      },
      "source": [
        "z = torch.randn(100, 62, 1, 1, device=device)\n",
        "fixed_noise = z\n",
        "idx = np.arange(10).repeat(10)\n",
        "dis_c = torch.zeros(100, 1, 10, device=device)\n",
        "for i in range(1):\n",
        "    dis_c[torch.arange(0, 100), i, idx] = 1.0\n",
        "\n",
        "dis_c = dis_c.view(100, -1, 1, 1)\n",
        "\n",
        "con_c = torch.rand(100, 2, 1, 1, device=device) * 2 - 1\n",
        "fixed_noise = torch.cat((fixed_noise, dis_c, con_c), dim=1).squeeze()\n",
        "# fixed_noise.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reHlWMIoZiA7"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  Dis_loss=0\n",
        "  G_loss=0\n",
        "  Discrete_loss=0\n",
        "  Cont_loss=0\n",
        "  for i, (data,_) in enumerate(train_loader):\n",
        "    data = data.to(device)\n",
        "    bs = data.size(0)\n",
        "    noise = torch.FloatTensor(bs,62).uniform_(-1.0,1.0).to(device)\n",
        "    cont = torch.FloatTensor(bs,2).uniform_(-1.0,1.0).to(device)\n",
        "    dis_c = torch.FloatTensor(bs,10).to(device)\n",
        "    z, id = noise_function(noise,cont,dis_c,bs,device)\n",
        "    ##discriminator\n",
        "    optimizer_d.zero_grad()\n",
        "    comm1 = netDQ_common(data)\n",
        "    D_x = netDis(comm1)\n",
        "    real_loss = criterion(D_x,real_label)\n",
        "    real_loss.backward()\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    # print(z.shape)\n",
        "    G_z = netGenerator(z)\n",
        "    comm2 = netDQ_common(G_z.detach())\n",
        "    DG_z = netDis(comm2)\n",
        "    fake_loss = criterion(DG_z,fake_label)\n",
        "    fake_loss.backward()\n",
        "    dis_loss = (real_loss+fake_loss)\n",
        "    # dis_loss.backward()\n",
        "    optimizer_d.step()\n",
        "    Dis_loss+=(dis_loss.item())\n",
        "\n",
        "    #generator\n",
        "    optimizer_g.zero_grad()\n",
        "    # gen_z = netGenerator(z)\n",
        "    comm3 = netDQ_common(G_z)\n",
        "    Dgen_z = netDis(comm3)\n",
        "    g_loss = criterion(Dgen_z, real_label)\n",
        "    G_loss+=(g_loss.item())\n",
        "    #Q\n",
        "    pred_c = netQhead(comm3)\n",
        "    discrete_loss = criterionQ_dis(pred_c[:,:10],id)\n",
        "    con_loss = criterionQ_con(z[:,-2:], pred_c[:,10:])*0.1 #criterionQ_con(z[:,-2:], pred_c[:,10:], pred_c[:,10:])*0.1\n",
        "    Discrete_loss+=(discrete_loss.item())\n",
        "    Cont_loss+=(con_loss.item())\n",
        "\n",
        "    gen_loss = g_loss + discrete_loss + con_loss\n",
        "    gen_loss.backward()\n",
        "    optimizer_g.step()\n",
        "\n",
        "    # if i%300==0:\n",
        "      \n",
        "\n",
        "  print('Epoch{}/{}: Discriminator loss:{:.6f}, Generator loss:{:.6f}, Discrete loss:{:.6f}, Continious loss:{:.6f}'.format(\n",
        "      epoch+1, epochs, Dis_loss/(bs*len(train_loader)), G_loss/(bs*len(train_loader)), Discrete_loss/(bs*len(train_loader)), Cont_loss/(bs*len(train_loader)) ))\n",
        "  # with torch.no_grad():\n",
        "  #   sample = netGenerator(z)\n",
        "  path = '/content/drive/MyDrive/VAE/InfoGAN/' + str(epoch+1) + '.png'\n",
        "  # save_image(sample, path, nrow=10)\n",
        "  print('Testing on Fixed data')\n",
        "  with torch.no_grad():\n",
        "    gen_data = netGenerator(fixed_noise).detach().cpu()\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n",
        "  plt.savefig(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GJQgFcRZiHS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3qcOigxZiKl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15xAJW-MZiOf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}